---
title: "KNN.Rmd"
author: KDR
date: "2/11/2020"
output: word_document
---

# K- Nearest Neighbor




###  Explore and prepare data by using the str() function. 

###### By reviewing the data, it's noticable that the first variable will be of not use as it carries multiple numberic digits (ID) to distinguish itself, thus might provide inaccurate results if left in the function. Thus, it has been dropped from the dataset prior to proceeding and the new data set is left with 31 variables and 569 observations. By reviewing a table of the target variable; diagnosis, it displays 357 observations as B (Benign) and 212 observations as M (Malignant.)

```{r}
wbcd <- read.csv('/Users/kris/Documents/wisc_bc_data.csv')

# We are droping ID variable; not useful.
wbcd <- wbcd[-1]

# Investigate using table function. 
table(wbcd$diagnosis) # 357 benign, 212 malignant.

# In ML, the target variable is coded as a factor.  
str(wbcd) # Diagnosis is coded as a factor. 
```
### Display the probability of the attributes ('Benign'and 'Malignant') of the variable named "diagnosis" that we plan to use for prediction. 

###### Above, we saw the counts of B and M. After implementing a proporton table, we convert the counts to a percentage and find that 62.7% of the diagnosis are Benign, and 37.3% are Malignant. 
```{r}
# Let's convert M and B to a percentage. 
round(prop.table(table(wbcd$diagnosis))*100, digits=1) # 62.7% B, and 37.3% M.

# The knn classifier is heavily dependent upon the measurement scale.
# We look at the summary, as it will show any issues.
# Here we see that the means are far apart. 

summary(wbcd[c("radius_mean", "area_mean", "smoothness_mean")])
str(wbcd)
# Scale is important, so let's normalize prior to moving to knn classifier. 
# Normaalize function:
# We only apply to variables 2:31 since 1 is our target variable (factor)

normalize <- function(x){
  return((x-min(x))/(max(x)-min(x)))
}

wbcd_n <- as.data.frame(lapply(wbcd[2:31], normalize))

#head(wbcd_n)

#summary(wbcd_n$area_mean)
 

```

### Create datasets for "training [1:469]" and "testing [470:569]" the model, and develop the model using the knn classifier algorithm. Evaluate the model with different k, and propose the best value of k.


###### When applying K of 3, prediction accuracy equals 94%.
###### When applying K of 1, prediction accuracy equals 93%.
###### When applying K of 2, prediction accuracy equals 93%.
###### When applying K of 4, prediction accuracy equals 95%.
###### When applying K of 5, prediction accuracy equals 97%.

###### When applying K of 7, prediction accuracy equals 98%. With 75 Benign objects predicted, and only 2 inaccuracies when pridicting Melign objects. 

###### Thus, best model is k=7. 
```{r}
#str(wbcd_n) # 569 obs, 30 vars.
# adding Dx back in.
wbcd_n2 <- cbind(wbcd_n, diagnosis = wbcd$diagnosis)
#t(t(names(wbcd_n2))) # diagnosis is now column 31. 



trainSet <- wbcd_n[1:469, ] # Assign rows 1-469 using the dataset w/ 30 Vars.
testSet <- wbcd_n[470:569, ] # Asign rows 470-569 using the dataset with 30 Vars.




data.trainLabels <-wbcd_n2[1:469, 31]
data.testLabels <-wbcd_n2[470:569, 31]



#str(trainSet) # 469 obs.
#str(testSet) # 100 obs.

#print(data.trainLabels)
#print(data.testLabels)


# Build the model (knn classifiers.) Make sure all training data is stored. No actual model or learning was performed up until now. 

library(class)

predict <-knn(train = trainSet, test=testSet, cl=data.trainLabels, k=7)
#predict

#install.packages("gmodels")
library(gmodels)

CrossTable(x=data.testLabels, y= predict)
library(caret)
confusionMatrix(data.testLabels, predict)
```
### Create datasets for "training [1:469]" and "testing [470:569]" the model, and develop the model using the knn classifier algorithm. Evaluate the model with different k, and propose the best value of k.

```{r}
#Alternate:

#str(wbcd_n) # 569 obs, 30 vars.
# adding Dx back in.
wbcd_n2 <- cbind(wbcd_n, diagnosis = wbcd$diagnosis)
#t(t(names(wbcd_n2))) # diagnosis is now column 31. 


  
set.seed(123)


idx <- sample(c("train", "test"), nrow(wbcd_n2),
              replace=TRUE, prob = (c(80, 20)))


trainSet<-wbcd_n2[idx=="train", 1:30]
testSet<-wbcd_n2[idx=="test",1:30]


# Compose "diagnosis" training labels
data.trainLabels <-wbcd_n2[idx=="train", 31]
# Compose "diagnosis" test labels
data.testLabels <-wbcd_n2[idx=="test", 31]

library(class)

predict <-knn(train = trainSet, test=testSet, cl=data.trainLabels, k=7)
#predict

#install.packages("gmodels")
library(gmodels)

CrossTable(x=data.testLabels, y= predict)
library(caret)
confusionMatrix(data.testLabels, predict)

```

---
title: "OnlineShopperIntentions"
output: pdf_document
date: "2024-09-27"
---

TASK: Find the best performing prediction model for the data set of interest. Once model is selected, you can then input the known independent variables and run the model, which will then output the prediction/expected upcoming value. 

```{r}
data <- read.csv("/Users/kdr/Documents/AmazonInfo/AmazonDatasets/online_shoppers_intention.csv")

# Review data (column names, data types, number of observations/rows and variables/columns.) "Revenue" is my prediction variable.

str(data)


# Separate into testing and training datasets: 

#install.packages('caret', dependencies = TRUE)
library(caret)
set.seed(12345)

# Partition data

intrain <- createDataPartition(y=Data$Revenue, p=0.7, list = FALSE)
trainSet <- data[intrain,]
testSet <- data[-intrain,]
summary(trainSet)
summary(testSet)
```

```{r}

# Prediction model using Bayes' Theorem: 

library(e1071)

# Train the model and inform of variable of interest
nb.model <- naiveBayes(Revenue~., data = trainSet)
nb.model


# Prediction function applied to the test data set:
nb.model.pred <- predict(nb.model, testSet, type = 'class')
nb.model.pred


# Validate the model with the confusion matrix:

actual <- as.factor(testSet$Revenue)
confusionMatrix(actual, nb.model.pred)

# RESULT: 80.99% ACCURACY


```



```{r}
# Prediction Model using Decision Tree (supervised classification method)

# DT using C5.0 

str(data) #12330 rows, 18 columns

# Update datatypes, if needed
data$Revenue<-as.factor(data$Revenue)
data$Weekend<-as.factor(data$Weekend)
set.seed(1234)

# Selecting 10,000 out of 12,330
train_sample <- sample(12330, 10000)
str(train_sample)
train<-data[train_sample,]
test<-data[-train_sample,]

library(C50)
DT_model <- C5.0(train[-18], train$Revenue)
DT_model
summary(DT_model)


purchase_predict <- predict(DT_model, test)
summary(purchase_predict)
table(test$Revenue)
library(gmodels)
CrossTable(test$Revenue, purchase_predict, porp.chisq=FASLE, dnn=c('actual purchase', 'predicted_purcahse'))

# RESULT: 90.13% ACCURACY

```


```{r}
# DT Classification method using tree, r-part, party and packages

# TREE package

library(caret)
set.seed(1234)

# if you need to drop a column:
# data <- data[,-1] # drops first column
partition <- createDataPartition(y=data$Revenue, p=0.7, list= FALSE)
train <- data[partition,]
test <- data[-partition,]
str(train)
str(test)

# Build the model:

install.packages('tree', dependencies = TRUE)
library(tree)
treemod <- tree(Revenue~., data=train)
plot(treemod)
text(treemod)

# If too many variables/overfitting, use cross validation
cv.trees <- cv.tree(treemod, FUN=prune.misclass)
plot(cv.trees)
# results: 3, 4, 5 are least dispursed, so we can use this to prune the DT

prune.trees <- prune.misclass(treemod, best = 5)

# Now we can see which predictors work best for out DT
plot(prune.trees)
text(prune.trees, pretty = 0)

# Now, evaluate the performance of the pruned DT with the Confusion Matrix

# Predict and evaluate
library(e1071)
library(caret)
treepred <- predict(prune.trees, test, type = 'class')
confusionMatrix(treepred, test$Revenue)

# RESULTS 88.72% ACCURACY in determining if the online visitor will make a purchase.

```

```{r}
# rpart Package
library(rpart)
rpartmod <- rpart(Revenue~., data = train, method = 'class')
plot(rpartmod)
text(rpartmod)

# Prune again for overfitting
# Printcp is used for crossvalidation, similar to cv.tree used above
printcp(rpartmod)
ptree <- prune(rpartmod, cp= rpartmod$cptable[which.min(rpartmod$cptable[,"xerror"]), "CP"])
plot(ptree)
text(ptree)

# Select the lowest Xerror from the table -5 in this case- and rebuild the model. 
# A low X-Error indicates that the modelâ€™s predictions are closely aligned with actual outcomes, suggesting high accuracy. Conversely, a high X-Error signals potential issues with the model, such as overfitting or underfitting. 

# X-Error, often referred to in the context of statistical analysis and data science, is a term that denotes the difference between the predicted values generated by a model and the actual observed values. 

# Predict and evaluate

rpartpred<-predict(ptree, test, type = 'class')
confusionMatrix(rpartpred, test$Revenue)

# RESULT: 90.02% ACCURACY

```


```{r}
# party package 
#install.packages('party', dependencies = TRUE)
library(party)

#update data types, if needed:
str(data)

partymod<-ctree(Revenue~., data=train)
plot(partymod)

# No need to prune with the party package b/c it's created using p value/statistical significance.

# error: character not supported, so drop Month (column 11) -or update data type- and rerun the above. 
data <- data[,-11] # drops 11th column
data <- data[,-15]

train <- train[,-11]
train <- train[,-15]

test <- test[,-11]
test <- test[,-15]

str(test)

partypred <- predict(partymod, test)
confusionMatrix(partypred, test$Revenue)

# RESULT: 89.16% ACCURACY


# BEST PERFORMING MODEL: C50 package (90.13%)

```
















